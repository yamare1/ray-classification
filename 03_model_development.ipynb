{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0dad688",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3464c92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n",
      "fLength     0\n",
      "fWidth      0\n",
      "fSize       0\n",
      "fConc       0\n",
      "fConc1      0\n",
      "fAsym       0\n",
      "fM3Long     0\n",
      "fM3Trans    0\n",
      "fAlpha      0\n",
      "fDist       0\n",
      "class       0\n",
      "dtype: int64\n",
      "\n",
      "Dataset Information:\n",
      "Number of samples: 19020\n",
      "Number of features: 10\n",
      "Class distribution:\n",
      "class\n",
      "1    64.84\n",
      "0    35.16\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Summary Statistics:\n",
      "            fLength        fWidth         fSize         fConc        fConc1  \\\n",
      "count  19020.000000  19020.000000  19020.000000  19020.000000  19020.000000   \n",
      "mean      53.250154     22.180966      2.825017      0.380327      0.214657   \n",
      "std       42.364855     18.346056      0.472599      0.182813      0.110511   \n",
      "min        4.283500      0.000000      1.941300      0.013100      0.000300   \n",
      "25%       24.336000     11.863800      2.477100      0.235800      0.128475   \n",
      "50%       37.147700     17.139900      2.739600      0.354150      0.196500   \n",
      "75%       70.122175     24.739475      3.101600      0.503700      0.285225   \n",
      "max      334.177000    256.382000      5.323300      0.893000      0.675200   \n",
      "\n",
      "              fAsym       fM3Long      fM3Trans        fAlpha         fDist  \\\n",
      "count  19020.000000  19020.000000  19020.000000  19020.000000  19020.000000   \n",
      "mean      -4.331745     10.545545      0.249726     27.645707    193.818026   \n",
      "std       59.206062     51.000118     20.827439     26.103621     74.731787   \n",
      "min     -457.916100   -331.780000   -205.894700      0.000000      1.282600   \n",
      "25%      -20.586550    -12.842775    -10.849375      5.547925    142.492250   \n",
      "50%        4.013050     15.314100      0.666200     17.679500    191.851450   \n",
      "75%       24.063700     35.837800     10.946425     45.883550    240.563825   \n",
      "max      575.240700    238.321000    179.851000     90.000000    495.561000   \n",
      "\n",
      "              class  \n",
      "count  19020.000000  \n",
      "mean       0.648370  \n",
      "std        0.477492  \n",
      "min        0.000000  \n",
      "25%        0.000000  \n",
      "50%        1.000000  \n",
      "75%        1.000000  \n",
      "max        1.000000  \n",
      "\n",
      "Training set shape: (13314, 10)\n",
      "Testing set shape: (5706, 10)\n"
     ]
    }
   ],
   "source": [
    "column_names = ['fLength', 'fWidth', 'fSize', 'fConc', 'fConc1', \n",
    "               'fAsym', 'fM3Long', 'fM3Trans', 'fAlpha', 'fDist', 'class']\n",
    "\n",
    "df = pd.read_csv('magic04.data', names=column_names)\n",
    "\n",
    "df['class'] = df['class'].map({'g': 1, 'h': 0})\n",
    "\n",
    "print(\"Missing values in each column:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(\"\\nDataset Information:\")\n",
    "print(f\"Number of samples: {df.shape[0]}\")\n",
    "print(f\"Number of features: {df.shape[1] - 1}\")\n",
    "print(f\"Class distribution:\\n{df['class'].value_counts(normalize=True).mul(100).round(2)}\")\n",
    "\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "X = df.drop('class', axis=1)\n",
    "y = df['class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"\\nTraining set shape: {X_train.shape}\")\n",
    "print(f\"Testing set shape: {X_test.shape}\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f1e094",
   "metadata": {},
   "source": [
    "### Define models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "713ccc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'Support Vector Machine': SVC(probability=True, random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "param_grids = {\n",
    "    'Logistic Regression': {\n",
    "        'C': [0.01, 0.1, 1, 10, 100],\n",
    "        'solver': ['liblinear', 'saga']\n",
    "    },\n",
    "    'K-Nearest Neighbors': {\n",
    "        'n_neighbors': [3, 5, 7, 9, 11, 13],\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'metric': ['euclidean', 'manhattan']\n",
    "    },\n",
    "    'Support Vector Machine': {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'kernel': ['linear', 'rbf'],\n",
    "        'gamma': ['scale', 'auto', 0.1, 0.01]\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_depth': [None, 10, 20],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    },\n",
    "    'Gradient Boosting': {\n",
    "        'n_estimators': [100, 200],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'subsample': [0.8, 1.0]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ea14a0",
   "metadata": {},
   "source": [
    "### Model Performance Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7155c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    return {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'ROC AUC': roc_auc\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b53daa",
   "metadata": {},
   "source": [
    "### Cross Validation and hyperparameter tuning to get best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05bc91b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Logistic Regression...\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Best parameters for Logistic Regression: {'C': 0.1, 'solver': 'saga'}\n",
      "Best cross-validation ROC AUC: 0.8442\n",
      "Test set performance for Logistic Regression:\n",
      "  Accuracy: 0.7808\n",
      "  Precision: 0.7923\n",
      "  Recall: 0.8970\n",
      "  F1 Score: 0.8414\n",
      "  ROC AUC: 0.8276\n",
      "\n",
      "Training K-Nearest Neighbors...\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Best parameters for K-Nearest Neighbors: {'metric': 'manhattan', 'n_neighbors': 13, 'weights': 'distance'}\n",
      "Best cross-validation ROC AUC: 0.9037\n",
      "Test set performance for K-Nearest Neighbors:\n",
      "  Accuracy: 0.8412\n",
      "  Precision: 0.8214\n",
      "  Recall: 0.9649\n",
      "  F1 Score: 0.8874\n",
      "  ROC AUC: 0.8990\n",
      "\n",
      "Training Support Vector Machine...\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yonathanamare/.venvs/ds/lib/python3.13/site-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Support Vector Machine: {'C': 10, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "Best cross-validation ROC AUC: 0.9218\n",
      "Test set performance for Support Vector Machine:\n",
      "  Accuracy: 0.8747\n",
      "  Precision: 0.8613\n",
      "  Recall: 0.9616\n",
      "  F1 Score: 0.9087\n",
      "  ROC AUC: 0.9284\n",
      "\n",
      "Training Random Forest...\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "Best parameters for Random Forest: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Best cross-validation ROC AUC: 0.9329\n",
      "Test set performance for Random Forest:\n",
      "  Accuracy: 0.8840\n",
      "  Precision: 0.8848\n",
      "  Recall: 0.9441\n",
      "  F1 Score: 0.9134\n",
      "  ROC AUC: 0.9374\n",
      "\n",
      "Training Gradient Boosting...\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Best parameters for Gradient Boosting: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200, 'subsample': 0.8}\n",
      "Best cross-validation ROC AUC: 0.9328\n",
      "Test set performance for Gradient Boosting:\n",
      "  Accuracy: 0.8894\n",
      "  Precision: 0.8918\n",
      "  Recall: 0.9441\n",
      "  F1 Score: 0.9172\n",
      "  ROC AUC: 0.9380\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "best_models = {}\n",
    "model_results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    \n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=param_grids[name],\n",
    "        cv=cv,\n",
    "        scoring='roc_auc',\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    grid_search.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_models[name] = best_model\n",
    "    \n",
    "    model_results[name] = evaluate_model(best_model, X_test_scaled, y_test)\n",
    "    \n",
    "    print(f\"Best parameters for {name}: {grid_search.best_params_}\")\n",
    "    print(f\"Best cross-validation ROC AUC: {grid_search.best_score_:.4f}\")\n",
    "    print(f\"Test set performance for {name}:\")\n",
    "    for metric, value in model_results[name].items():\n",
    "        print(f\"  {metric}: {value:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
