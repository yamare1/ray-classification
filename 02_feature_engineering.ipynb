{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3193943",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67b6386",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c026570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n",
      "fLength     0\n",
      "fWidth      0\n",
      "fSize       0\n",
      "fConc       0\n",
      "fConc1      0\n",
      "fAsym       0\n",
      "fM3Long     0\n",
      "fM3Trans    0\n",
      "fAlpha      0\n",
      "fDist       0\n",
      "class       0\n",
      "dtype: int64\n",
      "\n",
      "Dataset Information:\n",
      "Number of samples: 19020\n",
      "Number of features: 10\n",
      "Class distribution:\n",
      "class\n",
      "1    64.84\n",
      "0    35.16\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Summary Statistics:\n",
      "            fLength        fWidth         fSize         fConc        fConc1  \\\n",
      "count  19020.000000  19020.000000  19020.000000  19020.000000  19020.000000   \n",
      "mean      53.250154     22.180966      2.825017      0.380327      0.214657   \n",
      "std       42.364855     18.346056      0.472599      0.182813      0.110511   \n",
      "min        4.283500      0.000000      1.941300      0.013100      0.000300   \n",
      "25%       24.336000     11.863800      2.477100      0.235800      0.128475   \n",
      "50%       37.147700     17.139900      2.739600      0.354150      0.196500   \n",
      "75%       70.122175     24.739475      3.101600      0.503700      0.285225   \n",
      "max      334.177000    256.382000      5.323300      0.893000      0.675200   \n",
      "\n",
      "              fAsym       fM3Long      fM3Trans        fAlpha         fDist  \\\n",
      "count  19020.000000  19020.000000  19020.000000  19020.000000  19020.000000   \n",
      "mean      -4.331745     10.545545      0.249726     27.645707    193.818026   \n",
      "std       59.206062     51.000118     20.827439     26.103621     74.731787   \n",
      "min     -457.916100   -331.780000   -205.894700      0.000000      1.282600   \n",
      "25%      -20.586550    -12.842775    -10.849375      5.547925    142.492250   \n",
      "50%        4.013050     15.314100      0.666200     17.679500    191.851450   \n",
      "75%       24.063700     35.837800     10.946425     45.883550    240.563825   \n",
      "max      575.240700    238.321000    179.851000     90.000000    495.561000   \n",
      "\n",
      "              class  \n",
      "count  19020.000000  \n",
      "mean       0.648370  \n",
      "std        0.477492  \n",
      "min        0.000000  \n",
      "25%        0.000000  \n",
      "50%        1.000000  \n",
      "75%        1.000000  \n",
      "max        1.000000  \n",
      "\n",
      "Training set shape: (13314, 10)\n",
      "Testing set shape: (5706, 10)\n"
     ]
    }
   ],
   "source": [
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"viridis\")\n",
    "\n",
    "\n",
    "column_names = ['fLength', 'fWidth', 'fSize', 'fConc', 'fConc1', \n",
    "               'fAsym', 'fM3Long', 'fM3Trans', 'fAlpha', 'fDist', 'class']\n",
    "\n",
    "df = pd.read_csv('magic04.data', names=column_names)\n",
    "\n",
    "df['class'] = df['class'].map({'g': 1, 'h': 0})\n",
    "\n",
    "print(\"Missing values in each column:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(\"\\nDataset Information:\")\n",
    "print(f\"Number of samples: {df.shape[0]}\")\n",
    "print(f\"Number of features: {df.shape[1] - 1}\")\n",
    "print(f\"Class distribution:\\n{df['class'].value_counts(normalize=True).mul(100).round(2)}\")\n",
    "\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "X = df.drop('class', axis=1)\n",
    "y = df['class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"\\nTraining set shape: {X_train.shape}\")\n",
    "print(f\"Testing set shape: {X_test.shape}\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87c5a47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89be24c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "728962b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polynomial features/interaction terms"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
